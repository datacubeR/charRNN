{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from utils import import_text, create_vocabulary\n",
    "from dataset import QuijoteSeqDataset\n",
    "from model import CharRNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from train import fit_model\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DON QUIJOTE DE LA MANCHA\n",
      "Miguel de Cervantes Saavedra\n",
      "\n",
      "PRIMERA PARTE\n",
      "CAPÍTULO 1: Que trata de la condición y ejercicio del famoso hidalgo D. Quijote de la Mancha\n",
      "En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivía un hidalgo de los de lanza en astillero, adarga\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 1018041)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = import_text(\"el_quijote.txt\")\n",
    "print(text[:300]), len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0cÁ¡é‘–É’«“í¿»úñóÍü”áà'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = create_vocabulary(text)\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizador\n",
    "Un tokenizador corresponde a una función que nos permite convertir un texto en una secuencia de números y viceversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizer import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(vocabulary)\n",
    "tokenizer.n_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28, 14, 113, 24, 27, 73, 94, 110, 26, 30, 102, 94, 29, 10, 21, 82]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secuencia_ejemplo = tokenizer.text_to_seq(\"señor, ¿qué tal?\")\n",
    "secuencia_ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'señor, ¿qué tal?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.seq_to_text(secuencia_ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1018041"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = tokenizer.text_to_seq(text)\n",
    "len(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"abcdefghij\"\n",
    "\n",
    "\n",
    "def create_sequences(text, window_size=3):\n",
    "    text_windows = []\n",
    "    for i in range(len(text) - window_size + 1):\n",
    "        text_windows.append(text[i : i + window_size])\n",
    "    return text_windows\n",
    "\n",
    "\n",
    "encoded_windows = create_sequences(encoded_text, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(814432, 203609)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train, text_val = train_test_split(\n",
    "    encoded_text, test_size=0.2, random_state=RANDOM_SEED, shuffle=False\n",
    ")\n",
    "len(text_train), len(text_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "![](embeddings.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharRNN(tokenizer.n_vocabulary)\n",
    "sample_tensor = torch.randint(0, tokenizer.n_vocabulary, (32, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dict(\n",
    "    train=QuijoteSeqDataset(text_train, window_size=100),\n",
    "    val=QuijoteSeqDataset(text_val, window_size=100),\n",
    ")\n",
    "\n",
    "model = CharRNN(tokenizer.n_vocabulary)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in cuda\n",
      "Making NVIDIA GeForce RTX 2070 with Max-Q Design go brrruuummmmm....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.1824: 100%|██████████| 1590/1590 [02:24<00:00, 10.99it/s]\n",
      "Validation Loss: 1.8607: 100%|██████████| 100/100 [00:12<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30, Train Loss: 2.1824, Val Loss: 1.8607\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.7404: 100%|██████████| 1590/1590 [02:29<00:00, 10.62it/s]\n",
      "Validation Loss: 1.6453: 100%|██████████| 100/100 [00:12<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/30, Train Loss: 1.7404, Val Loss: 1.6453\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.5871: 100%|██████████| 1590/1590 [02:29<00:00, 10.65it/s]\n",
      "Validation Loss: 1.5416: 100%|██████████| 100/100 [00:12<00:00,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/30, Train Loss: 1.5871, Val Loss: 1.5416\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4984: 100%|██████████| 1590/1590 [02:29<00:00, 10.66it/s]\n",
      "Validation Loss: 1.4708: 100%|██████████| 100/100 [00:12<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/30, Train Loss: 1.4984, Val Loss: 1.4708\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4377: 100%|██████████| 1590/1590 [02:29<00:00, 10.65it/s]\n",
      "Validation Loss: 1.4304: 100%|██████████| 100/100 [00:12<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/30, Train Loss: 1.4377, Val Loss: 1.4304\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3936: 100%|██████████| 1590/1590 [02:29<00:00, 10.65it/s]\n",
      "Validation Loss: 1.3966: 100%|██████████| 100/100 [00:12<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/30, Train Loss: 1.3936, Val Loss: 1.3966\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3590: 100%|██████████| 1590/1590 [02:28<00:00, 10.72it/s]\n",
      "Validation Loss: 1.3714: 100%|██████████| 100/100 [00:12<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/30, Train Loss: 1.3590, Val Loss: 1.3714\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3303: 100%|██████████| 1590/1590 [02:25<00:00, 10.93it/s]\n",
      "Validation Loss: 1.3519: 100%|██████████| 100/100 [00:12<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/30, Train Loss: 1.3303, Val Loss: 1.3519\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3058: 100%|██████████| 1590/1590 [02:25<00:00, 10.93it/s]\n",
      "Validation Loss: 1.3344: 100%|██████████| 100/100 [00:13<00:00,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/30, Train Loss: 1.3058, Val Loss: 1.3344\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2853: 100%|██████████| 1590/1590 [02:24<00:00, 10.99it/s]\n",
      "Validation Loss: 1.3211: 100%|██████████| 100/100 [00:12<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/30, Train Loss: 1.2853, Val Loss: 1.3211\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2676: 100%|██████████| 1590/1590 [02:25<00:00, 10.96it/s]\n",
      "Validation Loss: 1.3120: 100%|██████████| 100/100 [00:12<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/30, Train Loss: 1.2676, Val Loss: 1.3120\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2507: 100%|██████████| 1590/1590 [02:24<00:00, 10.97it/s]\n",
      "Validation Loss: 1.3023: 100%|██████████| 100/100 [00:12<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/30, Train Loss: 1.2507, Val Loss: 1.3023\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2370: 100%|██████████| 1590/1590 [02:25<00:00, 10.94it/s]\n",
      "Validation Loss: 1.2930: 100%|██████████| 100/100 [00:12<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/30, Train Loss: 1.2370, Val Loss: 1.2930\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2230: 100%|██████████| 1590/1590 [02:28<00:00, 10.67it/s]\n",
      "Validation Loss: 1.2813: 100%|██████████| 100/100 [00:12<00:00,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/30, Train Loss: 1.2230, Val Loss: 1.2813\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2115: 100%|██████████| 1590/1590 [02:27<00:00, 10.81it/s]\n",
      "Validation Loss: 1.2784: 100%|██████████| 100/100 [00:12<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/30, Train Loss: 1.2115, Val Loss: 1.2784\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1998: 100%|██████████| 1590/1590 [02:26<00:00, 10.83it/s]\n",
      "Validation Loss: 1.2739: 100%|██████████| 100/100 [00:12<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/30, Train Loss: 1.1998, Val Loss: 1.2739\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1898: 100%|██████████| 1590/1590 [02:30<00:00, 10.59it/s]\n",
      "Validation Loss: 1.2704: 100%|██████████| 100/100 [00:12<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/30, Train Loss: 1.1898, Val Loss: 1.2704\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1794: 100%|██████████| 1590/1590 [02:29<00:00, 10.64it/s]\n",
      "Validation Loss: 1.2646: 100%|██████████| 100/100 [00:12<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/30, Train Loss: 1.1794, Val Loss: 1.2646\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1709: 100%|██████████| 1590/1590 [02:30<00:00, 10.56it/s]\n",
      "Validation Loss: 1.2628: 100%|██████████| 100/100 [00:12<00:00,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/30, Train Loss: 1.1709, Val Loss: 1.2628\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1615: 100%|██████████| 1590/1590 [02:32<00:00, 10.44it/s]\n",
      "Validation Loss: 1.2587: 100%|██████████| 100/100 [00:12<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/30, Train Loss: 1.1615, Val Loss: 1.2587\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1531: 100%|██████████| 1590/1590 [02:34<00:00, 10.29it/s]\n",
      "Validation Loss: 1.2560: 100%|██████████| 100/100 [00:12<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/30, Train Loss: 1.1531, Val Loss: 1.2560\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1454: 100%|██████████| 1590/1590 [02:34<00:00, 10.29it/s]\n",
      "Validation Loss: 1.2554: 100%|██████████| 100/100 [00:12<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/30, Train Loss: 1.1454, Val Loss: 1.2554\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1376: 100%|██████████| 1590/1590 [02:34<00:00, 10.29it/s]\n",
      "Validation Loss: 1.2546: 100%|██████████| 100/100 [00:12<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/30, Train Loss: 1.1376, Val Loss: 1.2546\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1308: 100%|██████████| 1590/1590 [02:33<00:00, 10.33it/s]\n",
      "Validation Loss: 1.2537: 100%|██████████| 100/100 [00:12<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/30, Train Loss: 1.1308, Val Loss: 1.2537\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1235: 100%|██████████| 1590/1590 [02:25<00:00, 10.95it/s]\n",
      "Validation Loss: 1.2526: 100%|██████████| 100/100 [00:12<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/30, Train Loss: 1.1235, Val Loss: 1.2526\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1162: 100%|██████████| 1590/1590 [02:28<00:00, 10.70it/s]\n",
      "Validation Loss: 1.2509: 100%|██████████| 100/100 [00:12<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/30, Train Loss: 1.1162, Val Loss: 1.2509\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1096: 100%|██████████| 1590/1590 [02:28<00:00, 10.74it/s]\n",
      "Validation Loss: 1.2510: 100%|██████████| 100/100 [00:12<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/30, Train Loss: 1.1096, Val Loss: 1.2510\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1035: 100%|██████████| 1590/1590 [02:30<00:00, 10.60it/s]\n",
      "Validation Loss: 1.2494: 100%|██████████| 100/100 [00:12<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/30, Train Loss: 1.1035, Val Loss: 1.2494\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.0972: 100%|██████████| 1590/1590 [02:31<00:00, 10.48it/s]\n",
      "Validation Loss: 1.2503: 100%|██████████| 100/100 [00:12<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/30, Train Loss: 1.0972, Val Loss: 1.2503\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.0912: 100%|██████████| 1590/1590 [02:34<00:00, 10.29it/s]\n",
      "Validation Loss: 1.2510: 100%|██████████| 100/100 [00:12<00:00,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/30, Train Loss: 1.0912, Val Loss: 1.2510\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_params = dict(\n",
    "    batch_size_train=512, batch_size_val=2048, lr=3e-4, epochs=30\n",
    ")\n",
    "model, loss = fit_model(model, dataset, training_params, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import CharRNN\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CharRNN(tokenizer.n_vocabulary)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(\"CharRNN_30.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, encoded_text):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X = torch.tensor(encoded_text).unsqueeze(0).to(device)\n",
    "        pred = model(X)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En un lugar de la mancha, y en el mundo que estaba en la mano de la mano de la mano de la mano de la mano de la mano de la mano de la mano.\n",
      "-úQu” te parece -dijo don Quijote-, y que es muy bien como es el mismo que le habÉa de ser muy bien en el mundo. Pero estos dÉas de los de los caballeros andantes de la mano de la mano de la mano de la mano de la mano de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la cabeza de la\n"
     ]
    }
   ],
   "source": [
    "initial_text = \"En un lugar de la mancha, \"\n",
    "\n",
    "\n",
    "def generate_text(model, initial_text, chars_to_generate):\n",
    "    for _ in range(chars_to_generate):\n",
    "        X_encoded = tokenizer.text_to_seq(initial_text[-100:])\n",
    "        y_pred = predict(model, X_encoded)\n",
    "        y_pred = torch.argmax(y_pred, axis=1).item()\n",
    "        initial_text += tokenizer.seq_to_text([y_pred])\n",
    "\n",
    "    return initial_text\n",
    "\n",
    "\n",
    "print(generate_text(model, initial_text, chars_to_generate=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En un lugar de la mancha, y de manera que el cura le dijo:\n",
      "-Pues a mi se pareciÍ -dijo el cabreroé, que es muy bien que se me deja mi parte de la muerte, y que es menester que se le habÉa de perder en el mundo. Y en esto se puso en la mano de los tres de mi padre, y asÉ como los deseos hasta la vida de la mano a su parecer del pastor de la mano, y la honra de mi buen padre en el mundo, y por ser sus manos en el suelo al caso en la mano de la cabeza de la mano de la muerte de la mano; y asÉ como en la mano de la venta y el cura le dijo que no se podÉa ser estado, y asÉ le dijo que estaba en la mano de su amo en la memoria de la mano de su seíora Dulcinea del Toboso, y en el alma en la venta de la cabeza de la cabeza y de desengaío de su padre y en la venta de su amo y de su casa de la cabeza de la cabeza de la cabeza de la cabeza, y que el deseo de haber contado a la cabeza de la memoria de la mano, y en el mundo estü en el mundo que no se pudiera servir a la vida de la vida y a su padre le dijo: ñSi no hay para\n"
     ]
    }
   ],
   "source": [
    "def generate_probabilistic_text(\n",
    "    model, initial_text, chars_to_generate, temp=1\n",
    "):\n",
    "    for i in range(chars_to_generate):\n",
    "        X_new_encoded = tokenizer.text_to_seq(initial_text[-100:])\n",
    "        y_pred = predict(model, X_new_encoded)\n",
    "        y_pred = y_pred.view(-1).div(temp).exp()\n",
    "        top_i = torch.multinomial(y_pred, 1).item()\n",
    "        predicted_char = tokenizer.seq_to_text([top_i])\n",
    "        initial_text += predicted_char\n",
    "    return initial_text\n",
    "\n",
    "\n",
    "temp = 0.3\n",
    "initial_text = \"En un lugar de la mancha, \"\n",
    "print(\n",
    "    generate_probabilistic_text(\n",
    "        model, initial_text, chars_to_generate=1000, temp=temp\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
